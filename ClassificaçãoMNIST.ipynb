{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "g157h0iWFHJE"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNOFCWkqTEzXheHsdZuAwF0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Baldros/Livros-IA/blob/main/Classifica%C3%A7%C3%A3oMNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sumário:\n",
        "\n",
        "    O primeiro capítulo do livro aborda a construção de Redes neurais\n",
        "    para reconhecimento de manuscritos. Deste modo abordando:\n",
        "\n",
        "    1. Introduz o Conceito de Perceptron: A unidade fundamental de\n",
        "    uma rede neural, tecnica criada por Frank Rosenblatt na década de 50.\n",
        "\n",
        "    2. Introduz a Sigmoid como função de ativação: A função de ativação,\n",
        "    ou função deslinearizadora é fundamental para aumentar o escopo de\n",
        "    aprendizado do modelo.\n",
        "\n",
        "    3. Introduz o aprendizado por Gradiente Descendente: O algorítmo de\n",
        "    Gradiente Descendente é um dos principais métodos de aprendizado\n",
        "    de muitos modelos de aprendizado de máquina e aqui não é diferente.\n",
        "\n",
        "Livro: http://neuralnetworksanddeeplearning.com/chap1.html"
      ],
      "metadata": {
        "id": "oNOenD_u91Cb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparando o ambiente:\n",
        "\n",
        "    Para realizarmos nosso estudos, vamos trabalhar em cima do\n",
        "    MNIST que um grande banco de dados de dígitos manuscritos,\n",
        "    comumente usado para treinar vários sistemas de processamento\n",
        "    de imagens. O banco de dados também é amplamente utilizado para\n",
        "    treinamento e teste no campo do aprendizado de máquina.\n",
        "\n",
        "Link: https://pt.wikipedia.org/wiki/Banco_de_dados_MNIST\n",
        "\n",
        "    Dito isso, precisamos preparar o ambiente para o estudo, o que\n",
        "    consiste basicamente em adiquirir o dataset."
      ],
      "metadata": {
        "id": "g157h0iWFHJE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando o conjunto de dados:\n",
        "!git clone https://github.com/mnielsen/neural-networks-and-deep-learning.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gv3shsbHEx9r",
        "outputId": "deaeaff6-aeea-45b5-873d-632efaf43237"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'neural-networks-and-deep-learning' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "    Nessa parte, o livro não trabalha com nenhuma ferramenta\n",
        "    especializada em Deep Learning, como Pytorch ou Tensorflow,\n",
        "    trabalhando apenas como o Numpy para a algebra linear."
      ],
      "metadata": {
        "id": "t8nyB-LdInNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Package para algebra linear:\n",
        "import numpy as np\n",
        "\n",
        "# Packages para visualização de dados:\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "from graphviz import Digraph"
      ],
      "metadata": {
        "id": "FBDzquoNE7YS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Construindo a nossa Rede Neural:\n",
        "\n",
        "    Tendo preparado o ambiente, podemos então começar a\n",
        "    elaborar a nossa rede neural. Não só nesse livro, mas\n",
        "    geralmente a implementação é estruturada em forma de\n",
        "    classes, o que será feito aqui também.\n",
        "\n",
        "    Mas isso não significa que uma rede neural não possa\n",
        "    ser implementada numa linguagem sem orientação a objeto.\n",
        "    Tudo que importa aqui é a matemática, como os principios\n",
        "    matemáticos serão abordados, pouco importa."
      ],
      "metadata": {
        "id": "h1Lj3qE1JWYT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Elementos do Multilayer Perceptron**\n",
        "\n",
        "    O primeiro passo aqui é construir o nosso multilayer perceptron"
      ],
      "metadata": {
        "id": "xDjYju0nb-YE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando a Classe:\n",
        "class RedeNeural(object):\n",
        "  '''\n",
        "    Classe que construtora da nossa rede neural.\n",
        "  '''\n",
        "  def __init__(self, qtd_neuron):\n",
        "    '''\n",
        "      Método construtor do nosso MLP, Multlayer Perceptron.\n",
        "    Aqui constará os parâmetros que serão utilizados para\n",
        "    gerar a nossa rede neural.\n",
        "    '''\n",
        "    self.num_camadas = len(qtd_neuron)\n",
        "    self.qtd_neuron = qtd_neuron\n",
        "    self.vieses = [np.random.randn(y,1) for y in qtd_neuron[1:]] # Note que não há viés na camada 0\n",
        "    self.pesos = [np.random.randn(y,x) for x, y in zip(qtd_neuron[:-1], qtd_neuron[1:])]"
      ],
      "metadata": {
        "id": "0x5a5LIVJNZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parâmetro *qtd_neuron*:\n",
        "\n",
        "    O parametro qtd_neuron serve para definir a quantidade de neurônio\n",
        "    em cada camada. Ou seja, ela é uma vetor onde cada entrada do vetor\n",
        "    contém o numero de neurônios naquela respectiva camada.\n",
        "\n",
        "Note:\n",
        "\n",
        "    Note que tantos os viéses e os pesos são inicializados aleatóriamente,\n",
        "    de modo que geral uma distribuição normal padrão, ou seja, uma gaussiana\n",
        "    de média = 0 e desvio padrão = 1. Esta inicialização aleatória dá ao\n",
        "    algoritmo gradiente descendente, que é um algorítmo estocastico, uma\n",
        "    condição inicial razoável.\n",
        "\n",
        "    Observe também que o que o código de inicialização da rede assume\n",
        "    que o primeira camada de neurônios é uma camada de entrada e omite\n",
        "    a definição de quaisquer vieses para esses neurônios, uma vez que\n",
        "    vieses só são usados ​​no cálculo das saídas das camadas posteriores\n"
      ],
      "metadata": {
        "id": "_B2l_JrUL3oj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo:\n",
        "MLP = RedeNeural([3,2,1]);MLP"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nn1L2KVwM7Er",
        "outputId": "786f78c3-2a65-471f-b24c-6595090f7b01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.RedeNeural at 0x793130ce9300>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "    Podemos checar então os atributos da nossa rede."
      ],
      "metadata": {
        "id": "65faKtkSYRwI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pesos:\n",
        "MLP.pesos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbG8IqfCKPz6",
        "outputId": "8c911c6b-94fd-4e2d-90a0-2716fa295be2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[ 1.13094391,  0.58244192,  0.73387569],\n",
              "        [-0.86836404,  0.13022435,  0.75249338]]),\n",
              " array([[0.84546192, 1.35452529]])]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Viéses\n",
        "MLP.vieses"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktJKRYDaYKM8",
        "outputId": "b59ca92a-fae9-4c7d-a8a6-37c134a2c3aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[ 0.70043116],\n",
              "        [-2.03185177]]),\n",
              " array([[-0.6733732]])]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Função de Ativação**\n",
        "\n",
        "    Criado o nosso método construtor da classe, que é o nosso método\n",
        "    de configuração do nosso MLP, precisamos então pensar na nossa\n",
        "    função deslinearizadora. O livro implementa a sigmoid, que é\n",
        "    baseada no conceito de entropia cruzada.\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "    Onde temos, que:\n",
        "    \n",
        "![image.png](data:image/png;base64,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)\n",
        "    \n",
        "    Além da sigmoid, apresentada no livro, eu vou aprensentar\n",
        "    a relu, que é outra função de ativação, uma boa opção e\n",
        "    de implementação fácil."
      ],
      "metadata": {
        "id": "ejkfzmdfZqRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Complementando a classe com as funções de ativação sigmoid:\n",
        "class RedeNeural(object):\n",
        "  '''\n",
        "    Classe que construtora da nossa rede neural.\n",
        "  '''\n",
        "\n",
        "  # Multlayer Perceptrion:\n",
        "  def __init__(self, qtd_neuron):\n",
        "    '''\n",
        "      Método construtor do nosso MLP, Multlayer Perceptron.\n",
        "    Aqui constará os parâmetros que serão utilizados para\n",
        "    gerar a nossa rede neural.\n",
        "    '''\n",
        "    self.num_camadas = len(qtd_neuron)\n",
        "    self.qtd_neuron = qtd_neuron\n",
        "    self.vieses = [np.random.randn(y,1) for y in qtd_neuron[1:]] # Note que não há viés na camada 0\n",
        "    self.pesos = [np.random.randn(y,x) for x, y in zip(qtd_neuron[:-1], qtd_neuron[1:])]\n",
        "\n",
        "  # Funções de Ativação:\n",
        "  def sigmoid(self, z):\n",
        "    '''\n",
        "      Função logistica utilzada aqui\n",
        "    para deslinearizar o perceptron.\n",
        "    '''\n",
        "    return 1/(1+np.exp(-z))"
      ],
      "metadata": {
        "id": "YVPCxCz6lN-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sigmoid**\n",
        "\n",
        "    O livro define a aplicação da sigmoid como neuronio sigmoid e faz\n",
        "    distinção entre esse neuronio sigmoid e o neuronio perceptron.\n",
        "    \n",
        "![image.png](data:image/png;base64,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)    \n",
        "    \n",
        "    Eu entendi o que ele quis dizer, até que faz sentido sim, porem, por\n",
        "    nunca ter visto nenhuma outra literatura usando essa definição, vou\n",
        "    tratar como a maioria faz. O neuronio é o perceptron e a sigmoid,\n",
        "    como todas as outras funções de ativação, é um processo executado\n",
        "    na ultima camada, resultando na resposta final."
      ],
      "metadata": {
        "id": "TrRTKycKmGjB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Complementando a classe com as funções de ativação relu:\n",
        "class RedeNeural(object):\n",
        "  '''\n",
        "    Classe que construtora da nossa rede neural.\n",
        "  '''\n",
        "\n",
        "  # Multlayer Perceptrion:\n",
        "  def __init__(self, qtd_neuron):\n",
        "    '''\n",
        "      Método construtor do nosso MLP, Multlayer Perceptron.\n",
        "    Aqui constará os parâmetros que serão utilizados para\n",
        "    gerar a nossa rede neural.\n",
        "    '''\n",
        "    self.num_camadas = len(qtd_neuron)\n",
        "    self.qtd_neuron = qtd_neuron\n",
        "    self.vieses = [np.random.randn(y,1) for y in qtd_neuron[1:]] # Note que não há viés na camada 0\n",
        "    self.pesos = [np.random.randn(y,x) for x, y in zip(qtd_neuron[:-1], qtd_neuron[1:])]\n",
        "\n",
        "  # Funções de Ativação:\n",
        "  def sigmoid(self, z):\n",
        "    '''\n",
        "      Função logistica utilzada aqui\n",
        "    para deslinearizar o perceptron.\n",
        "    '''\n",
        "    return 1/(1+np.exp(-z))\n",
        "\n",
        "  def relu(self,z):\n",
        "    '''\n",
        "      A função relu, tipo um gate,\n",
        "    dislinearizando o perceptron.\n",
        "    '''\n",
        "\n",
        "    if z > 0:\n",
        "      return z\n",
        "    else:\n",
        "      return 0"
      ],
      "metadata": {
        "id": "05b-J4XppNJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Por que deslinearizar?**\n",
        "\n",
        "    Para ajustar o aprendizado da rede, de modo que não haja instabilidade\n",
        "    no processo de treinamento. Se você notar, uma rede neural até antes da\n",
        "    saída funciona como uma regressão linear (Inclusive, por isso do nome\n",
        "    \"função deslinearizadora\"). Ou seja, matemáticamente falando, se fossemos\n",
        "    ajustar os pesos (ou viéses) nesse processo linear, pequenas mudanças nos\n",
        "    parâmetros de pesos acarretariam em mudanças significativas no aprendizado\n",
        "    e ai o aprendizado da rede neural não ficaria fino o suficiente.\n",
        "\n",
        "    O processo de aprendizado de uma rede neural é justamente o processo de\n",
        "    ajustar os pesos, e o que gostaríamos é que pequenas mudança no peso cause\n",
        "    apenas uma mudança correspondente pequena na saída da rede. O problema é\n",
        "    que isso não é o que acontece quando nossa rede contém perceptrons.\n",
        "\n",
        "    \n"
      ],
      "metadata": {
        "id": "Kuq632VidSBd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feedforward**\n",
        "\n",
        "    Definido-se o funcionamento da rede, podemos então definir como é\n",
        "    feita a aquisição de resposta da rede. Basicamente o feedfoward trada\n",
        "    desse processo de aquisição de resposta pela rede.\n",
        "\n",
        "    Aqui vale uma nota, porque ele ajuda o processo de treinamento na\n",
        "    medida que ele gera dos dados de predição a serem avaliados mas dito\n",
        "    isso, esse processo não faz parte do treinamento do modelo."
      ],
      "metadata": {
        "id": "U_XY0Cplpa_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Complementando a classe com o feedforward:\n",
        "class RedeNeural(object):\n",
        "  '''\n",
        "    Classe que construtora da nossa rede neural.\n",
        "  '''\n",
        "\n",
        "  # Multlayer Perceptrion:\n",
        "  def __init__(self, qtd_neuron):\n",
        "    '''\n",
        "      Método construtor do nosso MLP, Multlayer Perceptron.\n",
        "    Aqui constará os parâmetros que serão utilizados para\n",
        "    gerar a nossa rede neural.\n",
        "    '''\n",
        "    self.num_camadas = len(qtd_neuron)\n",
        "    self.qtd_neuron = qtd_neuron\n",
        "    self.vieses = [np.random.randn(y,1) for y in qtd_neuron[1:]] # Note que não há viés na camada 0\n",
        "    self.pesos = [np.random.randn(y,x) for x, y in zip(qtd_neuron[:-1], qtd_neuron[1:])]\n",
        "\n",
        "  # Funções de Ativação:\n",
        "  def sigmoid(self, z):\n",
        "    '''\n",
        "      Função logistica utilzada aqui\n",
        "    para deslinearizar o perceptron.\n",
        "    '''\n",
        "    return 1/(1+np.exp(-z))\n",
        "\n",
        "  def relu(self,z):\n",
        "    '''\n",
        "      A função relu, tipo um gate,\n",
        "    dislinearizando o perceptron.\n",
        "    '''\n",
        "\n",
        "    if self.z > 0:\n",
        "      return z\n",
        "    else:\n",
        "      return 0\n",
        "\n",
        "  # Método de Feedforward:\n",
        "  def feedforward(self, entrada, funcao_ativacao):\n",
        "    '''\n",
        "      Função de treinamento do modelo, executa os\n",
        "    calculos, até a saída.\n",
        "    '''\n",
        "\n",
        "    # Feedfoward dado a função de ativação:\n",
        "    for b, w in zip(self.vieses, self.pesos):\n",
        "      if funcao_ativacao == 'sigmod':\n",
        "        saida = self.sigmoid(np.dot(w,entrada)+b)\n",
        "      elif funcao_ativacao == 'relu':\n",
        "        saida = self.relu(np.dot(w,self.entrada)+b)\n",
        "\n",
        "    return saida"
      ],
      "metadata": {
        "id": "WkL0DVtnf4cd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Treinamento da Rede:\n",
        "\n",
        "    Aqui é onde a mágica de fato acontece e onde encontra-se a parte\n",
        "    a maioria das definições que se houve sobre as redes neurais.\n",
        "    Aqui precisamos definir uma série de elementos para de fato\n",
        "    conseguirmos entender como uma rede neural aprense."
      ],
      "metadata": {
        "id": "_ljHe8uDUIqa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Função Custo**\n",
        "\n",
        "    A primeira coisa que precisamos definir é a função custo, também\n",
        "    chamada de função objetivo, que nada mais é a função que quantifica\n",
        "    o quão bem estamos atingindo esse objetivo.\n",
        "\n",
        "    A ideia central é encontrar os pesos e viéses (ou parâmetros) da rede\n",
        "    neural que minimizam essa função custo. A função custo é definida como\n",
        "    a média dos quadrados das diferenças entre a saída esperada da rede\n",
        "    (dada pelos dados de treinamento) e a saída real produzida pela rede\n",
        "    para esses mesmos dados.\n",
        "    \n",
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAANMAAAA8CAYAAAD8FY+OAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAABBdSURBVHhe7Z0LXM3nH8c/56RTSXeXzF2UikrZwoxcps115p7Inw0ztcyMuW4U//1nozG3jZhbbpEYQ+6xzLWyJIroRjfVUafO6fv/ndMvcqpTp07JPO+XJ7/f8zu/2/N5Ps/9lIA4wGAwqo2Q/5/BYFQTZiYGQ0MwMzEYGoKZicHQEMxMDIaGYGZiMDQEMxODoSGYmRgMDcHMxGBoCGYmBkNDMDMxGBqCmUnTyDJx5+xeBIY9QSEfxXgzYGbSELLYA1g4rh+cbDrBuf84fBscz8z0hsHMpCEEJp0xbtk+XIrYjcmtWbK+iTDVNYTQpDU6tDKGiN9nvHkwMzEYGoKZqc4gxdUFdhAJBBBoIuj0xqp41murTZiZ6gz10GHoWHQz4SQRaOGtwWtwLTkVqanqhfhT36GXGZP1VcBSvQ6h//Yc7N76Kax1CpF4eC4+/Smc64uZwcys8qFF7/nYPLc7tPlrMmoPZqY6hRDmg/2wf+VANBWKce1HN7ivuwUJf7RyaKGZrRUaMWVrHZbkdQ4dWE/bhoCvndCAknF01nB4BiWpNWelbW2LdvX4HUblEd/gavXP4e01FSMGjoLvaTUn3uW/nUjTiONCaOOSVXQ0ScbHaAoZiZOi6EZMGrf1MtK4IPrBZzOdjc/jY2oZWQLtnTWE+rt0InNtIem2eJtcB4+h/52X8B9QE+kDCnBvS9oCkND4PVr6VzZ/oBJIY+jIhr10XemUgivryNvvIimeSBJKq7w30PUCxaEqURWdX7lOBVdonbcfXSxKBApd5U0b+ETIDZpIbUfuJDG3LT4+jdo7L6FINdJHbTPlptymsON7actvWyjg0Dn6J7VkZpFRQpAXObXrQTM2nqeEKuajspAlHqOlo7pQU5E2OS4Op1LvmPeATq35hN6x6E7fnHhcymyvJeJr9EMfMxJCQNotR9LWe9XI+RzyzGIxOkCRWUi8g0ZYTKbDuYpDalINnV+1TrlBNNFiNAUUJQLtGGFBk58ngpSk0qKtgr/nkaPzdxRRE2aSplyiDZ/3Jlunj2jG4pW0fo0vzXRzpqaGA+m3lKIkkT3YREPMLWhiYFLNJFLOXhpr1ow+OVpeqSalB9tGUotmY2l38r/CTiRL+YM8O+qRgDOUvsMsOpla9ffSlJmqr/Mr1EmlmXhkjyl4ai9y3/VIrferlJmk8YE0xbYROc44SHEl83HuAZr4zhd0RlEyFVDY3I5k6LKSYnl3a5qC6wvJQb8PrX6k4hWlkbT0bQN6xyeSk0yZPEp7EEPR0dEVhBh6lFlDL1EFJNG/0bBm9ThDCamxqx+FV6k20ZSZNKSzSp1qkArNlEGX/jeOxq0Ioyw+prJUPAAhuw//6VOxp8l87Fo5FK11+Hg59Tpg2KyxcJCvoZHewpE/78GqnytaahUdViB7itgL+7Hz9H3I+CggH0+f5vHbMiSFHUTw9Yo7ezkREYgzt0VHo1REnjyAQ2EPUXyV52hZwbVfS0Qe/QP3X9ywCFksAua4w83NrYIwAUuPpfEnvXpElpPhv2ceuhoDj49/jREzApFYE/OxsgxEndiJHSH3SqRrIVKuhiA0NrtIn/J0VlCI7HtnsHtHCGKfXyAb0Sf34XB4+sv6qtKp2uQh8eYpHDr4J/6OjcbF4FDEV+Ye0ngEL5qF3ebzsHFWF+Qe2YqDCWokNG+qcsijvLNfUDvt1jTteA4fVw6Zv9NHBg3JPbCkywso4vcvaYitIekP20ZFV5BQ2DedqMGHv1KaYj+NNg2sT6KeP1KcyjqV6yzOsiJdm6H02fjRNHpED2qh14SG/BpbqmTL2jaMDMzcKVBR+vxbkNGjfZOovUhAEBpT98UX1S45VddM3PVP+NFcj27UuEFPWhHNpyrXYZ9vb0BtBq2iK/JWSZk6FyGN3U8Lxvemdvr69O73USSVpdHJOe+RZVMj0un2Xyq+ZDE1oVMB9wzeLvbU+1Mf2rBlEb3fUEja3b+nmOJ7l1szSegiV+MaNGpP9g4O5MAFqxa9afntytebqs0kCeUysCVpm0+kQxW8sDR6OXXVs6KvQpV7owV0bYE96fdbS4rmceoemthSl0TvreCbCRI6P7MDWc88z1lXBbJkWu+qT20nHaBExXm5FPJ5W9ItQ6S841M5o/WlNYm13B6vcXIp3K8/NRaChI1G0A41+xuVauZJ/qKvbQzogw3Jiv5CztEpZNPDh67x4pSvczG5XGFpR/rvfk+XD3jRmCWXKDPrLkXcK10Ya1wn8UVa0KUVDVh9i3sKOVm0/WNjsvQ+x+Uynsr0maqI6mZefhziYhOA5hawKNm8KwN6los80oWunvIlhTAxMQTEWXhKMkRtOQS9we+jQY58nzssvYNzUdbw9uoGlbcoiER4tDY69+2LpormhQjtLVtBmJGKNKUqXKCrBx3KhfiZ0t8kkEbip8HWsLS0rCDYYsK2FP6k0kyYMAFcyVWtsH79ev5q6qCLlk5d0NLYBlM2r8aYJjUwTSiyR89uhoi8ch0FhY8R6B8BV9+Z6MyLU77OxejCacJY2EVuwtTtpvjy664wMrBAx7b6/PEXlKlT3hF4dbYqQxPlYIvJARn8SXIKkbRrGdY+G41FU2y4p+DIj0LkHSE6vWNXK6v5K5jaK0QhV3sJdLnE42PKQ6CjA5EgH/n5ym1MuZmMIMjJRlbaEeyI6gGvEddx9Ggq0mWFSNi7CuH9l2J761IN8JcoTI7ArScW6Guvx8dIkZiQDGHzNmil9BaUn48CgQ50dQV8DA/Xx5uy5QzcCir6wx8C6Bg24rdLs2DBAojFYn6vajRt2pTfqjzSu/6Y5LYVTXxOwG+QeQ3NuIvg6GiNp9tuIDb2DvYXjIdfj/r8MVU6v0CrcVu0EsUhvN0HsFdRQpapk25fLDl2DvO4fKcaTiNjI35bTi7OnwiFyHkq7Iudk3kTNx9aoqdjAz6iZlGth64d7OysgJhw3Mzh44rJCcGSeXuQzKepVsNGMBU8RVpa6USQv7SeOA2XNx6CyaceaGtmigZP05GauB/LTzlgsadtRa5GfkQ47jSwhV0b/pOSq9h/OAldhw6AcgEtS0/DU21TNDRSfr16aGDWBObm5hWEJjCpX37SyEvGzp07VyvI76MOhWknMWfkXDwYsx3bplrXYEkrhJmjI1rcvYp9/qfRdLI7WpVIClU6FyHBlTX7Iehlh/jQ83ioouNftk66MG5SSY10S5xXKEZ6Rh70DQyeZ2pJxHXcNuoEhwoKak1Rfo6RU68jOk7ywgDBQfj6nMKTEoVR2qGNCEjRg3HxFYysYd0sA7F3H788asMhMDaBQeoRbM8YihnOutAyNYZhbhQ2LwjB2ws/g7XCH4V4fG41Zs9eg3Mlb6RAhvvht5DVvhM6KUq6Zwj/ZRH2GH4Bn0mt8XJSyfDgThwkbWxgo1ydyh7i8HJveHp6VhBmYvW5TP6kOoAkEmvdJyLQcgX2LnOBfGF5TSLq6IiOshNYe6UrZnxgwMfylKNz4ZPLOHDsFu4Ff4Mljz7G8tn90fpaALZF5vOfUEaFTlVBaITWrUyRfPUS7nK3LMwIw3q/w0hs3BItKyqpNUQFsmhBq9UEbD7gC5vTE+DoNBDjp03HJ2MHYciKOHTvY/+ihBQ5ol9PU4SfPYuSLVk5gvr60ONquf94DoApt69lYgIjYQ6aj/wO49sUW0GKmD+3Y+dv8zB/axwfVwxB1tACbWL84Ob+OWZMHod5V/vA/8AiOL9ogRRRmIKz52+jucv7sFFOREF9mFvZwd7evoJgB4uGtdHKrgSFSQjyHAXfnKkI2DQez5OrJtHjCi3LRhjoOQW2yvcrR+dn5/wwZbAz+vxsgJnLR6KV03h80u0+Vgzqi/EL9uC2lP9gMap0qhI66Oc1H30eLkX3drbo6nEIzQf3gkn4ariPmI41F5RzZQ3AD0RUAillxv9DN65H0r3EzBejIyWQ/L2QOpt2J98bKsflVFBANxd3J9fV8fy+ElIxPY5PoAwVSzxy/ppPjibd6b+3Kj+kWVUKUiIoZP/vtHnbATodmcI9vabJocvLepG51WQKTFBnxCubEqLvU7rSA1V20jY3bBEN9NhF5Q2yla2zhNJT0pXyRS5lZZU96ldjOhVkUnJKNr9yIY9SHyVSVsl0qMHRPDXMVBmy6S+fntSs81TaFZmp1lIMuVnTr2+kSUO/ppMZfJRaSCntuj952DSn/j/d4IdGawox3fhlFDk5DaCpC5eTz8whZGVoTI7eh0lza3uldH+nG7V9qz+tUnPJgyxlPbkautDKBy8/TLlmkiXR6V/96UKajKSPguiLYdMrMG/1dK49ncrg9TGTnGz6Z99imjBwGv2uJKZKMi7Q1tWBFJ5Rtdwojd5A/xk0iXyD79a8QFk7aYSRNtnODeNrIynF/NSL9LVtaW5YefMv6pFxdh693cSevI+rvxhUcsaLLPRKmynv5GxymRFclD5cppruModOySuX7H3kZqZFxpbO9G7fT2nLrcqkYNV0rlWdyiLvJM12mUHBRYlAQdNdaI4iEapPDZjpDUB6jwK/+4p+Cnmx0FNycTZ10Nan4TsVRZ4CSVo0XfzjFP0j/ypEXgpFngqmk7fSKzSH5PZGGtqiJQ3bFF2FpqOMktf1J11RaTOpIvvuBTp2JpJSNJOv3kiYmTRE9n53aixyoEWK78bIKOnYUhrTpSmJjAbRt+vnksfo4fShnSlpmY6iXSqasbKUo+Rp14S6LrxAmXycOkgTguizTvokUNNMjOojkP/gxyIYVUUWi3UD34Gv8Wpc3jkWbynGSAvx8Od+sPSRYPq6rfAd3g6CE9PQfngSlsYHwcNYcebL5IVj5eB++Op0AVp0aA4DpTnnyiB5cg93U3JBIhesjAmBd8saHkdnvEBhKUY1yKbLvr2oueOXdPxxyZqAa497mFMTj6DnfYO0LUPI2H4hXSur7SZ7RPsntSeRAPLCrfqB1Uy1DquZqkU2rqwci/G72+OHwBUY9FaJSRlpOL517oYQt0icmdUGWpDgxDRLeEjWINZ/cOnlWflPcC86CWJNqSFogGbWbWFWSxOWDA6FpRjqI02go3NdqPPQH+lSOl8DZIbS5h3XiuZa0vxpiGFzmnKM79EXhNO3Tgb0/tpEtUfnGK8HrEFdFZ5exS9j+sLzRi/M+9IZsn8uITQ0FOcCVmPZvggUcB+RhF9DpNQKdp3432CX9Teu3DFFO0vTipadMF5XeFMx1CD91w9Jp7hvohR0hmylHK7uifuxJ+lZePFf6ZfPi/rTRyb1yNTuY/L6+XTRd7sY/ypYn6kWkYkzkCUwhEn92lhgx6htWIujFtHSN6m6kSTRcO36CfaliHFjnQd69JmPPvPP8wcZdQFWM71GXFn4HnwkA+DkMArTXLm+l9AAZiZsuK6uwGqm14hOfRwQdTwbrqMs0MjMhBmpjsHM9BoRfF4IB8MYRGUof3mSURdgZnodKEzE5nE9cL/PYsx9PwV+ny9HUNQzcP8YdQjWZ3pdyJcAIvl39mXIz+c2RWxEsK7BzMRgaAjWzGMwNAQzE4OhIZiZGAwNwczEYGgIZiYGQ0MwMzEYGoKZicHQCMD/AddvnSwBcR4UAAAAAElFTkSuQmCC)\n",
        "\n",
        "    Essa função custo é uma forma suave de medir o quão bem a rede está\n",
        "    performando, e é escolhida porque é diferenciável, o que facilita o\n",
        "    uso de técnicas como a descida do gradiente.\n",
        "\n",
        "**Stocastic Gradient Descendent**\n",
        "\n",
        "    O Stocastic Gradient Descendent (SGD) é o algorítmos que usaremos para\n",
        "    que consegamos ajustar o modelo. Ele é uma variação do algoritmo de\n",
        "    descida do gradiente utilizado para treinar redes neurais. A principal\n",
        "    diferença entre o SGD e o gradiente descendente tradicional é que o SGD\n",
        "    realiza a atualização dos parâmetros da rede neural de forma estocástica,\n",
        "    ou seja, em cada iteração do treinamento, os parâmetros são atualizados\n",
        "    com base em um único exemplo de treinamento aleatoriamente escolhido ou\n",
        "    em um pequeno conjunto de exemplos de treinamento (mini-batch), em vez\n",
        "    de utilizar o conjunto de dados completo.\n",
        "\n",
        "**Mini-Batchs**\n",
        "\n",
        "    Em vez de alimentar todos os dados de treinamento de uma vez só (batch\n",
        "    completo), o conjunto de dados de treinamento é dividido em pequenos\n",
        "    subconjuntos chamados de mini-batchs. Cada mini-batch contém um número\n",
        "    fixo de exemplos de treinamento.\n",
        "\n",
        "    Ao utilizar mini-batchs, o processo de treinamento é realizado\n",
        "    iterativamente em cada mini-batch. Isso oferece várias vantagens:\n",
        "\n",
        "    1. Eficiência computacional: Processar todos os exemplos de treinamento\n",
        "    de uma só vez pode ser computacionalmente custoso, especialmente para\n",
        "    conjuntos de dados grandes. O uso de mini-batchs permite distribuir o\n",
        "    processamento ao longo do tempo, tornando o treinamento mais eficiente.\n",
        "\n",
        "    2. Memória: Para conjuntos de dados muito grandes, pode ser difícil\n",
        "    armazenar todos os exemplos de treinamento na memória ao mesmo tempo.\n",
        "    Com mini-batchs, apenas um pequeno subconjunto dos dados precisa ser\n",
        "    carregado na memória de cada vez, tornando mais viável o treinamento\n",
        "    de redes neurais com grandes conjuntos de dados.\n",
        "\n",
        "    3. Estocasticidade: O termo \"estocástico\" em SGD refere-se à aleatoriedade\n",
        "    na seleção dos mini-batchs. Cada mini-batch é selecionado aleatoriamente\n",
        "    do conjunto de dados de treinamento em cada iteração. Isso introduz uma\n",
        "    variação estocástica no processo de treinamento, o que pode ajudar a\n",
        "    evitar mínimos locais e a promover uma exploração mais ampla do espaço\n",
        "    de parâmetros da rede neural.\n",
        "\n",
        "    4. Regularização: O uso de mini-batchs também pode fornecer um efeito\n",
        "    de regularização, pois os pesos da rede neural são atualizados com base\n",
        "    em uma estimativa do gradiente calculada em um subconjunto dos dados de\n",
        "    treinamento, em vez de utilizar o gradiente calculado em todo o conjunto\n",
        "    de dados. Isso introduz uma fonte de ruído nos gradientes, que pode\n",
        "    ajudar a prevenir o overfitting."
      ],
      "metadata": {
        "id": "zjEcLN0Jr6OL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Complementando a rede com o processo de Backpropagation:\n",
        "class RedeNeural(object):\n",
        "  '''\n",
        "    Classe que construtora da nossa rede neural.\n",
        "  '''\n",
        "\n",
        "  # Multlayer Perceptrion:\n",
        "  def __init__(self, qtd_neuron):\n",
        "    '''\n",
        "      Método construtor do nosso MLP, Multlayer Perceptron.\n",
        "    Aqui constará os parâmetros que serão utilizados para\n",
        "    gerar a nossa rede neural.\n",
        "    '''\n",
        "    self.num_camadas = len(qtd_neuron)\n",
        "    self.qtd_neuron = qtd_neuron\n",
        "    self.vieses = [np.random.randn(y,1) for y in qtd_neuron[1:]] # Note que não há viés na camada 0\n",
        "    self.pesos = [np.random.randn(y,x) for x, y in zip(qtd_neuron[:-1], qtd_neuron[1:])]\n",
        "\n",
        "  # Funções de Ativação:\n",
        "  def sigmoid(self, z):\n",
        "    '''\n",
        "      Função logistica utilzada aqui\n",
        "    para deslinearizar o perceptron.\n",
        "    '''\n",
        "    return 1/(1+np.exp(-z))\n",
        "\n",
        "  def relu(self,z):\n",
        "    '''\n",
        "      A função relu, tipo um gate,\n",
        "    dislinearizando o perceptron.\n",
        "    '''\n",
        "\n",
        "    if self.z > 0:\n",
        "      return z\n",
        "    else:\n",
        "      return 0\n",
        "\n",
        "  # Método de Feedforward:\n",
        "  def feedforward(self, entrada, funcao_ativacao):\n",
        "    '''\n",
        "      Função de treinamento do modelo, executa os\n",
        "    calculos, até a saída.\n",
        "    '''\n",
        "\n",
        "    # Feedfoward dado a função de ativação:\n",
        "    for b, w in zip(self.vieses, self.pesos):\n",
        "      if funcao_ativacao == 'sigmod':\n",
        "        saida = self.sigmoid(np.dot(w,entrada)+b)\n",
        "      elif funcao_ativacao == 'relu':\n",
        "        saida = self.relu(np.dot(w,self.entrada)+b)\n",
        "\n",
        "    return saida\n",
        "\n",
        "  # Treinamento da rede:\n",
        "  def SGD(self, training_data, epochs, mini_batch_size, eta, test_data=None):\n",
        "    '''\n",
        "      Treine a rede neural usando descida gradiente estocástica em minilote. O\n",
        "    \"training_data\" é uma lista de tuplas \"(x, y)\" representando o treinamento\n",
        "    entradas e as saídas desejadas. Os outros parâmetros não opcionais são auto-\n",
        "    explicativo. Se \"test_data\" for fornecido, a rede será avaliada\n",
        "    em relação aos dados de teste após cada época e o progresso parcial é impresso.\n",
        "    Isso é útil para monitorar o progresso, mas retarda substancialmente as coisas.\n",
        "    '''\n",
        "\n",
        "    if test_data:\n",
        "      n_test = len(test_data)\n",
        "      n = len(training_data)\n",
        "\n",
        "    for j in range(epochs):\n",
        "      np.random.suffler(training_data)\n",
        "      mini_batches = [training_data[k:k+mini_batch_size] for k in range(0,n,mini_batch_size)]\n",
        "      for mini_batch in mini_batches:\n",
        "        self.update_mini_batch(mini_batch, eta)\n",
        "\n",
        "      if test_data:\n",
        "        print(f'Epoch {j}: {self.evaluate(test_data)}, {n_test}')\n",
        "      else:\n",
        "        print(f'Epoch {j} complete')"
      ],
      "metadata": {
        "id": "yXyTOoO4rGBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Atualização dos valores**"
      ],
      "metadata": {
        "id": "xw0QvxqL4xs6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Complementando a rede com o processo de Backpropagation:\n",
        "class RedeNeural(object):\n",
        "  '''\n",
        "    Classe que construtora da nossa rede neural.\n",
        "  '''\n",
        "\n",
        "  # Multlayer Perceptrion:\n",
        "  def __init__(self, qtd_neuron):\n",
        "    '''\n",
        "      Método construtor do nosso MLP, Multlayer Perceptron.\n",
        "    Aqui constará os parâmetros que serão utilizados para\n",
        "    gerar a nossa rede neural.\n",
        "    '''\n",
        "    self.num_camadas = len(qtd_neuron)\n",
        "    self.qtd_neuron = qtd_neuron\n",
        "    self.vieses = [np.random.randn(y,1) for y in qtd_neuron[1:]] # Note que não há viés na camada 0\n",
        "    self.pesos = [np.random.randn(y,x) for x, y in zip(qtd_neuron[:-1], qtd_neuron[1:])]\n",
        "\n",
        "  # Funções de Ativação:\n",
        "  def sigmoid(self, z):\n",
        "    '''\n",
        "      Função logistica utilzada aqui\n",
        "    para deslinearizar o perceptron.\n",
        "    '''\n",
        "    return 1/(1+np.exp(-z))\n",
        "\n",
        "  def relu(self,z):\n",
        "    '''\n",
        "      A função relu, tipo um gate,\n",
        "    dislinearizando o perceptron.\n",
        "    '''\n",
        "\n",
        "    if self.z > 0:\n",
        "      return z\n",
        "    else:\n",
        "      return 0\n",
        "\n",
        "  # Método de Feedforward:\n",
        "  def feedforward(self, entrada, funcao_ativacao):\n",
        "    '''\n",
        "      Função de treinamento do modelo, executa os\n",
        "    calculos, até a saída.\n",
        "    '''\n",
        "\n",
        "    # Feedfoward dado a função de ativação:\n",
        "    for b, w in zip(self.vieses, self.pesos):\n",
        "      if funcao_ativacao == 'sigmod':\n",
        "        saida = self.sigmoid(np.dot(w,entrada)+b)\n",
        "      elif funcao_ativacao == 'relu':\n",
        "        saida = self.relu(np.dot(w,self.entrada)+b)\n",
        "\n",
        "    return saida\n",
        "\n",
        "  # Treinamento da Rede:\n",
        "  def SGD(self, training_data, epochs, mini_batch_size, eta, test_data=None):\n",
        "    '''\n",
        "      Treine a rede neural usando descida gradiente estocástica em minilote. O\n",
        "    \"training_data\" é uma lista de tuplas \"(x, y)\" representando o treinamento\n",
        "    entradas e as saídas desejadas. Os outros parâmetros não opcionais são auto-\n",
        "    explicativo. Se \"test_data\" for fornecido, a rede será avaliada\n",
        "    em relação aos dados de teste após cada época e o progresso parcial é impresso.\n",
        "    Isso é útil para monitorar o progresso, mas retarda substancialmente as coisas.\n",
        "    '''\n",
        "\n",
        "    if test_data:\n",
        "      n_test = len(test_data)\n",
        "      n = len(training_data)\n",
        "\n",
        "    for j in range(epochs):\n",
        "      np.random.suffler(training_data)\n",
        "      mini_batches = [training_data[k:k+mini_batch_size] for k in range(0,n,mini_batch_size)]\n",
        "      for mini_batch in mini_batches:\n",
        "        self.update_mini_batch(mini_batch, eta)\n",
        "\n",
        "      if test_data:\n",
        "        print(f'Epoch {j}: {self.evaluate(test_data)}, {n_test}')\n",
        "      else:\n",
        "        print(f'Epoch {j} complete')\n",
        "\n",
        "  # Mini_batch:\n",
        "  def update_mini_batch(self, mini_batch, eta):\n",
        "    '''\n",
        "      Atualize os pesos e tendências da rede aplicando gradiente descendente usando\n",
        "    retropropagação para um único minilote. O \"mini_batch\" é uma lista de tuplas\n",
        "    \"(x, y)\" e \"eta\" é a taxa de aprendizagem.\n",
        "    '''\n",
        "\n",
        "    nabla_b = [np.zeros(b.shape) for b in self. vieses]\n",
        "    nabla_w = [np.zeros(w.shape) for w in self.pesos]\n",
        "\n",
        "    for x,y in mini_batch:\n",
        "      delta_nabla_b, delta_nabla_w = self.backprop(x,y)\n",
        "      nabla_b = [nb + dnb for nb, dnb in zip(nabla_b,delta_nabla_b)]\n",
        "      nabla_w = [nw + dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
        "\n",
        "    self.pesos = [w - (eta/len(mini_batch))*nw for w, nw in zip(self.pesos,nabla_w)]\n",
        "    self.vieses = [b - (eta/len(mini_batch))*nb for b, nb in zip(self.vieses, nabla_b)]"
      ],
      "metadata": {
        "id": "SwCJ4PoBuXn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Backpropagation**\n",
        "\n",
        "    Definido-se os elementos do treinamneto, como a função custo e o\n",
        "    algorítmo de otimização da função custo, podemos então falar\n",
        "    do treinamento da rede, que ocorre por meio do backpropagation.\n",
        "\n",
        "    Dado o resultado obtido pelo feedforward e o quanto isso se\n",
        "    distancia da nosso resultado real, a ideia é ajustar os pesos\n",
        "    para que possamos melhorar a predição da nossa rede.\n"
      ],
      "metadata": {
        "id": "W81hiQtkcEpd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dependências utilizadas:\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# A Rede Neural:\n",
        "class RedeNeural(object):\n",
        "    '''\n",
        "    Classe construtora da nossa rede neural.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, tamanhos, funcao_ativacao='sigmoid'):\n",
        "        '''\n",
        "        Método construtor do MLP (Multilayer Perceptron).\n",
        "        Aqui constarão os parâmetros que serão utilizados para\n",
        "        gerar a nossa rede neural.\n",
        "        '''\n",
        "        self.num_camadas = len(tamanhos)\n",
        "        self.tamanhos = tamanhos\n",
        "        self.funcao_ativacao = funcao_ativacao\n",
        "        self.vieses = [np.random.randn(y, 1) for y in tamanhos[1:]]\n",
        "        self.pesos = [np.random.randn(y, x) for x, y in zip(tamanhos[:-1], tamanhos[1:])]\n",
        "\n",
        "    # Método de Feedforward:\n",
        "    def feedforward(self, entrada):\n",
        "        \"\"\"Retorna a saída da rede neural se 'entrada' for o input.\"\"\"\n",
        "\n",
        "        #\n",
        "        for b, w in zip(self.vieses, self.pesos):\n",
        "            entrada = self.ativacao(np.dot(w, entrada) + b)\n",
        "\n",
        "        return entrada\n",
        "\n",
        "    def SGD(self, dados_treinamento, epocas, tamanho_mini_batch, eta, dados_teste=None):\n",
        "        '''\n",
        "        Treina a rede neural usando descida gradiente estocástica em mini-lote.\n",
        "        \"dados_treinamento\" é uma lista de tuplas \"(x, y)\" representando as entradas\n",
        "        de treinamento e as saídas desejadas. Os outros parâmetros não opcionais são autoexplicativos.\n",
        "        Se \"dados_teste\" for fornecido, a rede será avaliada em relação aos dados de teste após cada época,\n",
        "        e o progresso parcial é impresso. Isso é útil para monitorar o progresso, mas retarda substancialmente as coisas.\n",
        "        '''\n",
        "        if dados_teste:\n",
        "            n_teste = len(dados_teste)\n",
        "        n = len(dados_treinamento)\n",
        "\n",
        "        for j in range(epocas):\n",
        "            random.shuffle(dados_treinamento)\n",
        "            mini_batches = [dados_treinamento[k:k + tamanho_mini_batch] for k in range(0, n, tamanho_mini_batch)]\n",
        "\n",
        "            for mini_batch in mini_batches:\n",
        "                self.atualiza_mini_batch(mini_batch, eta)\n",
        "\n",
        "            if dados_teste:\n",
        "                print(f'Época {j}: {self.avaliacao(dados_teste)/ n_teste}')\n",
        "            else:\n",
        "                print(f'Época {j} concluída')\n",
        "\n",
        "    def atualiza_mini_batch(self, mini_batch, eta):\n",
        "        '''\n",
        "        Atualiza os pesos e vieses da rede aplicando descida gradiente usando retropropagação para um único mini-lote.\n",
        "        O \"mini_batch\" é uma lista de tuplas \"(x, y)\" e \"eta\" é a taxa de aprendizagem.\n",
        "        '''\n",
        "        nabla_b = [np.zeros(b.shape) for b in self.vieses]\n",
        "        nabla_w = [np.zeros(w.shape) for w in self.pesos]\n",
        "\n",
        "        for x, y in mini_batch:\n",
        "            delta_nabla_b, delta_nabla_w = self.backprop(x, y)\n",
        "            nabla_b = [nb + dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
        "            nabla_w = [nw + dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
        "\n",
        "        self.pesos = [w - (eta / len(mini_batch)) * nw for w, nw in zip(self.pesos, nabla_w)]\n",
        "        self.vieses = [b - (eta / len(mini_batch)) * nb for b, nb in zip(self.vieses, nabla_b)]\n",
        "\n",
        "    def backprop(self, x, y):\n",
        "        '''\n",
        "        Retorna uma tupla \"(nabla_b , nabla_w)\" representando o\n",
        "        gradiente para a função de custo C_x. \"nabla_b\" e \"nabla_w\"\n",
        "        são listas camada por camada de matrizes numpy, semelhantes\n",
        "        para \"self.vieses\" e \"self.pesos\".\n",
        "        '''\n",
        "        nabla_b = [np.zeros(b.shape) for b in self.vieses]\n",
        "        nabla_w = [np.zeros(w.shape) for w in self.pesos]\n",
        "\n",
        "        # Feedforward\n",
        "        ativacao = x\n",
        "        ativacoes = [x]  # lista para armazenar todas as ativações, camada por camada\n",
        "        zs = []  # lista para armazenar todos os vetores z, camada por camada\n",
        "\n",
        "        for b, w in zip(self.vieses, self.pesos):\n",
        "            z = np.dot(w, ativacao) + b\n",
        "            zs.append(z)\n",
        "            ativacao = self.ativacao(z)\n",
        "            ativacoes.append(ativacao)\n",
        "\n",
        "        # Retropropagação\n",
        "        delta = self.derivada_custo(ativacoes[-1], y) * self.derivada_ativacao(zs[-1])\n",
        "\n",
        "        nabla_b[-1] = delta\n",
        "        nabla_w[-1] = np.dot(delta, ativacoes[-2].transpose())\n",
        "\n",
        "        for l in range(2, self.num_camadas):\n",
        "            z = zs[-l]\n",
        "            delta = np.dot(self.pesos[-l + 1].transpose(), delta) * self.derivada_ativacao(z)\n",
        "            nabla_b[-l] = delta\n",
        "            nabla_w[-l] = np.dot(delta, ativacoes[-l - 1].transpose())\n",
        "\n",
        "        return nabla_b, nabla_w"
      ],
      "metadata": {
        "id": "prxoZRic3FUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Código completo:\n",
        "\n",
        "    Deste modo, percorrido todos os pontos da contrução e do aprendizado\n",
        "    da rede neural, podemos então definir a sua classe de forma completa."
      ],
      "metadata": {
        "id": "XCU1vEPrxyC9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dependências utilizadas:\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# A Rede Neural:\n",
        "class RedeNeural(object):\n",
        "    '''\n",
        "    Classe construtora da nossa rede neural.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, tamanhos, funcao_ativacao='sigmoid'):\n",
        "        '''\n",
        "        Método construtor do MLP (Multilayer Perceptron).\n",
        "        Aqui constarão os parâmetros que serão utilizados para\n",
        "        gerar a nossa rede neural.\n",
        "        '''\n",
        "        self.num_camadas = len(tamanhos)\n",
        "        self.tamanhos = tamanhos\n",
        "        self.funcao_ativacao = funcao_ativacao\n",
        "        self.vieses = [np.random.randn(y, 1) for y in tamanhos[1:]]\n",
        "        self.pesos = [np.random.randn(y, x) for x, y in zip(tamanhos[:-1], tamanhos[1:])]\n",
        "\n",
        "    def feedforward(self, entrada):\n",
        "        \"\"\"Retorna a saída da rede neural se 'entrada' for o input.\"\"\"\n",
        "        for b, w in zip(self.vieses, self.pesos):\n",
        "            entrada = self.ativacao(np.dot(w, entrada) + b)\n",
        "\n",
        "        return entrada\n",
        "\n",
        "    def SGD(self, dados_treinamento, epocas, tamanho_mini_batch, eta, dados_teste=None):\n",
        "        '''\n",
        "        Treina a rede neural usando descida gradiente estocástica em mini-lote.\n",
        "        \"dados_treinamento\" é uma lista de tuplas \"(x, y)\" representando as entradas\n",
        "        de treinamento e as saídas desejadas. Os outros parâmetros não opcionais são autoexplicativos.\n",
        "        Se \"dados_teste\" for fornecido, a rede será avaliada em relação aos dados de teste após cada época,\n",
        "        e o progresso parcial é impresso. Isso é útil para monitorar o progresso, mas retarda substancialmente as coisas.\n",
        "        '''\n",
        "        if dados_teste:\n",
        "            n_teste = len(dados_teste)\n",
        "        n = len(dados_treinamento)\n",
        "\n",
        "        for j in range(epocas):\n",
        "            random.shuffle(dados_treinamento)\n",
        "            mini_batches = [dados_treinamento[k:k + tamanho_mini_batch] for k in range(0, n, tamanho_mini_batch)]\n",
        "\n",
        "            for mini_batch in mini_batches:\n",
        "                self.atualiza_mini_batch(mini_batch, eta)\n",
        "\n",
        "            if dados_teste:\n",
        "                print(f'Época {j}: {self.avaliacao(dados_teste)/ n_teste}')\n",
        "            else:\n",
        "                print(f'Época {j} concluída')\n",
        "\n",
        "    def atualiza_mini_batch(self, mini_batch, eta):\n",
        "        '''\n",
        "        Atualiza os pesos e vieses da rede aplicando descida gradiente usando retropropagação para um único mini-lote.\n",
        "        O \"mini_batch\" é uma lista de tuplas \"(x, y)\" e \"eta\" é a taxa de aprendizagem.\n",
        "        '''\n",
        "        nabla_b = [np.zeros(b.shape) for b in self.vieses]\n",
        "        nabla_w = [np.zeros(w.shape) for w in self.pesos]\n",
        "\n",
        "        for x, y in mini_batch:\n",
        "            delta_nabla_b, delta_nabla_w = self.backprop(x, y)\n",
        "            nabla_b = [nb + dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
        "            nabla_w = [nw + dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
        "\n",
        "        self.pesos = [w - (eta / len(mini_batch)) * nw for w, nw in zip(self.pesos, nabla_w)]\n",
        "        self.vieses = [b - (eta / len(mini_batch)) * nb for b, nb in zip(self.vieses, nabla_b)]\n",
        "\n",
        "    def backprop(self, x, y):\n",
        "        '''\n",
        "        Retorna uma tupla \"(nabla_b , nabla_w)\" representando o\n",
        "        gradiente para a função de custo C_x. \"nabla_b\" e \"nabla_w\"\n",
        "        são listas camada por camada de matrizes numpy, semelhantes\n",
        "        para \"self.vieses\" e \"self.pesos\".\n",
        "        '''\n",
        "        nabla_b = [np.zeros(b.shape) for b in self.vieses]\n",
        "        nabla_w = [np.zeros(w.shape) for w in self.pesos]\n",
        "\n",
        "        # Feedforward\n",
        "        ativacao = x\n",
        "        ativacoes = [x]  # lista para armazenar todas as ativações, camada por camada\n",
        "        zs = []  # lista para armazenar todos os vetores z, camada por camada\n",
        "\n",
        "        for b, w in zip(self.vieses, self.pesos):\n",
        "            z = np.dot(w, ativacao) + b\n",
        "            zs.append(z)\n",
        "            ativacao = self.ativacao(z)\n",
        "            ativacoes.append(ativacao)\n",
        "\n",
        "        # Retropropagação\n",
        "        delta = self.derivada_custo(ativacoes[-1], y) * self.derivada_ativacao(zs[-1])\n",
        "\n",
        "        nabla_b[-1] = delta\n",
        "        nabla_w[-1] = np.dot(delta, ativacoes[-2].transpose())\n",
        "\n",
        "        for l in range(2, self.num_camadas):\n",
        "            z = zs[-l]\n",
        "            delta = np.dot(self.pesos[-l + 1].transpose(), delta) * self.derivada_ativacao(z)\n",
        "            nabla_b[-l] = delta\n",
        "            nabla_w[-l] = np.dot(delta, ativacoes[-l - 1].transpose())\n",
        "\n",
        "        return nabla_b, nabla_w\n",
        "\n",
        "    def avaliacao(self, dados_teste):\n",
        "        '''\n",
        "        Retorna o número de entradas de teste para as quais a\n",
        "        rede neural produz o resultado correto. A saída da rede\n",
        "        neural é assumida como o índice do neurônio que tiver a\n",
        "        maior ativação na camada final.\n",
        "        '''\n",
        "        resultados_teste = [(np.argmax(self.feedforward(x)), y) for (x, y) in dados_teste]\n",
        "        return sum(int(x == y) for (x, y) in resultados_teste)\n",
        "\n",
        "    def derivada_custo(self, saida_ativacao, y):\n",
        "        '''\n",
        "        Retorna o vetor de derivadas parciais \\partial C_x /\n",
        "        \\partial a para as ativações de saída.\n",
        "        '''\n",
        "        return (saida_ativacao - y)\n",
        "\n",
        "    def derivada_ativacao(self, z):\n",
        "        '''\n",
        "        Retorna a derivada da função de ativação em z.\n",
        "        '''\n",
        "        if self.funcao_ativacao == 'sigmoid':\n",
        "            return sigmoid_prime(z)\n",
        "        elif self.funcao_ativacao == 'relu':\n",
        "            return relu_prime(z)\n",
        "\n",
        "    def ativacao(self, z):\n",
        "        '''\n",
        "        Retorna a função de ativação aplicada em z.\n",
        "        '''\n",
        "        if self.funcao_ativacao == 'sigmoid':\n",
        "            return sigmoid(z)\n",
        "        elif self.funcao_ativacao == 'relu':\n",
        "            return relu(z)"
      ],
      "metadata": {
        "id": "0bYLo8JkwLg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "    Eu mantive as funções de ativação fora da classe,\n",
        "    considerei mais facil de se implementar."
      ],
      "metadata": {
        "id": "4-xtNRkIXv0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fuinções de Ativação:\n",
        "def sigmoid(z):\n",
        "    \"\"\"The sigmoid function.\"\"\"\n",
        "    return 1.0 / (1.0 + np.exp(-z))\n",
        "\n",
        "def sigmoid_prime(z):\n",
        "    \"\"\"Derivative of the sigmoid function.\"\"\"\n",
        "    return sigmoid(z) * (1 - sigmoid(z))\n",
        "\n",
        "def relu(z):\n",
        "        '''\n",
        "        A função relu, atuando como um \"gate\", deslineariza o perceptron.\n",
        "        '''\n",
        "        return np.maximum(0, z)\n",
        "\n",
        "def relu_prime(z):\n",
        "    '''\n",
        "    Derivada da função relu.\n",
        "    '''\n",
        "    return np.where(z > 0, 1, 0)"
      ],
      "metadata": {
        "id": "bv9U-cF01MEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importando os dados:\n",
        "\n",
        "    Pela forma que os dados estão organizados, se faz necessário construir\n",
        "    um código para importar os dados. Aqui vamos construir esse código."
      ],
      "metadata": {
        "id": "amBlSgYdpLgp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard library\n",
        "import pickle\n",
        "import gzip"
      ],
      "metadata": {
        "id": "RDHX9psLoyQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        "    \"\"\"Return the MNIST data as a tuple containing the training data,\n",
        "    the validation data, and the test data.\n",
        "\n",
        "    The ``training_data`` is returned as a tuple with two entries.\n",
        "    The first entry contains the actual training images.  This is a\n",
        "    numpy ndarray with 50,000 entries.  Each entry is, in turn, a\n",
        "    numpy ndarray with 784 values, representing the 28 * 28 = 784\n",
        "    pixels in a single MNIST image.\n",
        "\n",
        "    The second entry in the ``training_data`` tuple is a numpy ndarray\n",
        "    containing 50,000 entries.  Those entries are just the digit\n",
        "    values (0...9) for the corresponding images contained in the first\n",
        "    entry of the tuple.\n",
        "\n",
        "    The ``validation_data`` and ``test_data`` are similar, except\n",
        "    each contains only 10,000 images.\n",
        "\n",
        "    This is a nice data format, but for use in neural networks it's\n",
        "    helpful to modify the format of the ``training_data`` a little.\n",
        "    That's done in the wrapper function ``load_data_wrapper()``, see\n",
        "    below.\n",
        "    \"\"\"\n",
        "\n",
        "    # Lendo os arquivos e extraindo a informação:\n",
        "    with gzip.open('neural-networks-and-deep-learning/data/mnist.pkl.gz', 'rb') as f:\n",
        "      training_data, validation_data, test_data = pickle.load(f, encoding='latin1')\n",
        "\n",
        "    return (training_data, validation_data, test_data)"
      ],
      "metadata": {
        "id": "38CCTholpdCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data_wrapper():\n",
        "    \"\"\"Return a tuple containing ``(training_data, validation_data,\n",
        "    test_data)``. Based on ``load_data``, but the format is more\n",
        "    convenient for use in our implementation of neural networks.\n",
        "\n",
        "    In particular, ``training_data`` is a list containing 50,000\n",
        "    2-tuples ``(x, y)``.  ``x`` is a 784-dimensional numpy.ndarray\n",
        "    containing the input image.  ``y`` is a 10-dimensional\n",
        "    numpy.ndarray representing the unit vector corresponding to the\n",
        "    correct digit for ``x``.\n",
        "\n",
        "    ``validation_data`` and ``test_data`` are lists containing 10,000\n",
        "    2-tuples ``(x, y)``.  In each case, ``x`` is a 784-dimensional\n",
        "    numpy.ndarry containing the input image, and ``y`` is the\n",
        "    corresponding classification, i.e., the digit values (integers)\n",
        "    corresponding to ``x``.\n",
        "\n",
        "    Obviously, this means we're using slightly different formats for\n",
        "    the training data and the validation / test data.  These formats\n",
        "    turn out to be the most convenient for use in our neural network\n",
        "    code.\"\"\"\n",
        "    tr_d, va_d, te_d = load_data()\n",
        "    training_inputs = [np.reshape(x, (784, 1)) for x in tr_d[0]] # Formatação das entradas de treinamento\n",
        "    training_results = [vectorized_result(y) for y in tr_d[1]] # Formatação dos resultados de treinamento\n",
        "    training_data = list(zip(training_inputs, training_results)) # Criação do conjunto de dados de treinamento\n",
        "    validation_inputs = [np.reshape(x, (784, 1)) for x in va_d[0]] # Formatação das entradas de validação\n",
        "    validation_data = list(zip(validation_inputs, va_d[1])) # Criação do conjunto de dados de validação\n",
        "    test_inputs = [np.reshape(x, (784, 1)) for x in te_d[0]] # Formatação das entradas de teste\n",
        "    test_data = list(zip(test_inputs, te_d[1])) # Criação do conjunto de dados de teste\n",
        "    return (training_data, validation_data, test_data)"
      ],
      "metadata": {
        "id": "uEESQg-uqCkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorized_result(j):\n",
        "    \"\"\"Return a 10-dimensional unit vector with a 1.0 in the jth\n",
        "    position and zeroes elsewhere.  This is used to convert a digit\n",
        "    (0...9) into a corresponding desired output from the neural\n",
        "    network.\"\"\"\n",
        "    e = np.zeros((10, 1)) # Cria um vetor de zeros com 10 dimensões\n",
        "    e[j] = 1.0  # Define o valor na posição j-ésima como 1.0\n",
        "    return e"
      ],
      "metadata": {
        "id": "uy2APZCfqEIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Treinando a Rede Neural:\n",
        "\n",
        "    Feito todos os preparativos, vamos fazer a mágica acontecer."
      ],
      "metadata": {
        "id": "Ju2WWSuaqNGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Separando os dados:\n",
        " training_data, validation_data, test_data = load_data_wrapper()"
      ],
      "metadata": {
        "id": "Ifu9agHIqIXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instanciando modelo:\n",
        "net = RedeNeural([784,30,10])"
      ],
      "metadata": {
        "id": "v6kk7ZgRsH9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "    Carregado os dados e instanciado o modelo, vamos utiliza o\n",
        "    algorítmo do Gradiente Descendente Estocastico para que a\n",
        "    rede aprenda com os dados de treino.\n",
        "\n",
        "    O livro trava com 30 épocas, com tamanho de mini batchs de 10\n",
        "    e taxa de aprendizado de η = 3,0"
      ],
      "metadata": {
        "id": "m4sE1w5YseG3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ajustando o modelo\n",
        "net.SGD(training_data , 30, 10, 3, dados_teste = test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKAaKJeTs3-5",
        "outputId": "0ae5d70e-4361-41bd-b9d6-9537c330feb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Época 0: 0.9134\n",
            "Época 1: 0.9179\n",
            "Época 2: 0.9303\n",
            "Época 3: 0.9313\n",
            "Época 4: 0.9361\n",
            "Época 5: 0.9376\n",
            "Época 6: 0.9427\n",
            "Época 7: 0.9406\n",
            "Época 8: 0.9448\n",
            "Época 9: 0.9433\n",
            "Época 10: 0.945\n",
            "Época 11: 0.9457\n",
            "Época 12: 0.9434\n",
            "Época 13: 0.9476\n",
            "Época 14: 0.9464\n",
            "Época 15: 0.948\n",
            "Época 16: 0.9479\n",
            "Época 17: 0.9472\n",
            "Época 18: 0.9453\n",
            "Época 19: 0.9468\n",
            "Época 20: 0.9482\n",
            "Época 21: 0.949\n",
            "Época 22: 0.9482\n",
            "Época 23: 0.9469\n",
            "Época 24: 0.9478\n",
            "Época 25: 0.9481\n",
            "Época 26: 0.9489\n",
            "Época 27: 0.9473\n",
            "Época 28: 0.9496\n",
            "Época 29: 0.949\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classificando imagens:\n",
        "\n",
        "    Com a rede treinada, podemos testar a classificação da nossa\n",
        "    rede e ver como ela se sai."
      ],
      "metadata": {
        "id": "rBXmiWWxEEMT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2"
      ],
      "metadata": {
        "id": "rZKtqX32x79w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Baixando imagem:\n",
        "!curl -o img.jpg https://d365e82sgxmduv.cloudfront.net/Custom/Content/Products/23/27/2327889_numero-7-em-acm-preto-185mm-685-7-numeral_m2_638103304639197088.jpg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snZyYujIEQ7m",
        "outputId": "0edf21ef-e84c-4077-a381-a6dd12006ad4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 19808  100 19808    0     0  17166      0  0:00:01  0:00:01 --:--:-- 17179\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar a imagem:\n",
        "imagem = cv2.imread('img.jpg', cv2.IMREAD_GRAYSCALE);imagem"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuiN4C0PO7CQ",
        "outputId": "e1665a4e-1e43-432d-85be-e4b04ae1aeee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[255, 255, 255, ..., 255, 255, 255],\n",
              "       [255, 255, 255, ..., 255, 255, 255],\n",
              "       [255, 255, 255, ..., 255, 255, 255],\n",
              "       ...,\n",
              "       [255, 255, 255, ..., 255, 255, 255],\n",
              "       [255, 255, 255, ..., 255, 255, 255],\n",
              "       [255, 255, 255, ..., 255, 255, 255]], dtype=uint8)"
            ],
            "text/html": [
              "<style>\n",
              "      .ndarray_repr .ndarray_raw_data {\n",
              "        display: none;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_raw_data {\n",
              "        display: block;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_image_preview {\n",
              "        display: none;\n",
              "      }\n",
              "      </style>\n",
              "      <div id=\"id-5be75c93-e8ba-4659-9d31-364e7acd46f4\" class=\"ndarray_repr\"><pre>ndarray (500, 500) <button style=\"padding: 0 2px;\">show data</button></pre><img src=\"data:image/png;base64,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\" class=\"ndarray_image_preview\" /><pre class=\"ndarray_raw_data\">array([[255, 255, 255, ..., 255, 255, 255],\n",
              "       [255, 255, 255, ..., 255, 255, 255],\n",
              "       [255, 255, 255, ..., 255, 255, 255],\n",
              "       ...,\n",
              "       [255, 255, 255, ..., 255, 255, 255],\n",
              "       [255, 255, 255, ..., 255, 255, 255],\n",
              "       [255, 255, 255, ..., 255, 255, 255]], dtype=uint8)</pre></div><script>\n",
              "      (() => {\n",
              "      const titles = ['show data', 'hide data'];\n",
              "      let index = 0\n",
              "      document.querySelector('#id-5be75c93-e8ba-4659-9d31-364e7acd46f4 button').onclick = (e) => {\n",
              "        document.querySelector('#id-5be75c93-e8ba-4659-9d31-364e7acd46f4').classList.toggle('show_array');\n",
              "        index = (++index) % 2;\n",
              "        document.querySelector('#id-5be75c93-e8ba-4659-9d31-364e7acd46f4 button').textContent = titles[index];\n",
              "        e.preventDefault();\n",
              "        e.stopPropagation();\n",
              "      }\n",
              "      })();\n",
              "    </script>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Redimensionar para 28x28 pixels\n",
        "imagem_redimensionada = cv2.resize(imagem, (1,784))"
      ],
      "metadata": {
        "id": "xWjiyzMnE2gc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "norm_vetor = imagem_redimensionada/np.max(imagem_redimensionada)"
      ],
      "metadata": {
        "id": "O6M_E4hgibkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Passar a imagem pela rede neural\n",
        "saida_rede = net.feedforward(norm_vetor)\n",
        "\n",
        "# Interpretar a saída da rede\n",
        "classe_predita = np.argmax(saida_rede)\n",
        "\n",
        "print(f\"A classe predita para a nova imagem é: {classe_predita}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDiu8In1FATW",
        "outputId": "cc14bccc-dee4-4c90-ac9f-d1b01f8524e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A classe predita para a nova imagem é: 7\n"
          ]
        }
      ]
    }
  ]
}